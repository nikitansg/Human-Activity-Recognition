# Human-Activity-Recognition

## Dataset
The dataset consists of the following features:

1. Tri-axial accelerometer and gyroscope readings
2. Subject information (volunteer identifier)
3. Activity labels (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
You can download the dataset from the UCI Machine Learning Repository.
Data source:https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones

## Project Structure
1. data/: directory for storing the dataset.
2. notebooks/: Jupyter notebooks for data exploration, preprocessing, and modeling
3. src/: Python scripts for data processing and machine learning models
4. requirements.txt: List of required Python libraries

## Getting Started
1. Clone this repository
 git clone https://github.com/your-username/Human-Activity-Recognition.git
 cd Human-Activity-Recognition
2. Create a virtual environment (optional but recommended)
 python -m venv venv
 source venv/bin/activate
3. Install the required Python libraries
 pip install -r requirements.txt

Download the dataset from the provided UCI repository link and place it in the data/ directory.
Explore the Jupyter notebooks in the notebooks/ directory to understand data preprocessing, analysis, and model building.
Execute the Python scripts in the src/ directory to perform specific tasks such as data preprocessing, model training, or evaluation 

## Usage
This project can be used as a foundation for building Human Activity Recognition systems. You can extend the code and models for your specific applications or research.

## Acknowledgments
Thanks to the UCI Machine Learning Repository for providing the dataset for this project.
Special thanks to the volunteers who participated in the experiments.
